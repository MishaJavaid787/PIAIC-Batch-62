{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM29frrTx5ObG3k7sZhWtq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MishaJavaid787/PIAIC-Batch-62/blob/main/Project_02_LangChain_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Packages**"
      ],
      "metadata": {
        "id": "4qWklL31L0i_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GGUeizfEKAP9"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ],
      "metadata": {
        "id": "6ohXU8MTMCcl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialize Pinecone**"
      ],
      "metadata": {
        "id": "fYPXIO1KR0mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "index_name = \"gemini-rag-project-1\"\n",
        "\n",
        "pc.create_index (\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "LIQpGGlwMLO0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYcBxA_HTK-A",
        "outputId": "5b73bce8-d61d-4776-a997-6a1a49c06911"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.35)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.10.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2txt\n",
        "from langchain.document_loaders import Docx2txtLoader\n",
        "\n",
        "# Use Docx2txtLoader instead of TextLoader\n",
        "loader = Docx2txtLoader(\"/content/DeepSeek_txt.docx\")\n",
        "documents = loader.load()\n",
        "\n",
        "# Split the documents into chunks\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"\\nChunk {i+1}:\\n{chunk.page_content}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oVIJwA0TlDlm",
        "outputId": "483a9787-fc63-4bfc-a5a4-e6c20b5e2996"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.11/dist-packages (0.8)\n",
            "\n",
            "Chunk 1:\n",
            "What is DeepSeek?\n",
            "\n",
            "DeepSeek is the name of a free AI-powered chatbot, which looks, feels and works very much like ChatGPT.\n",
            "\n",
            "That means it's used for many of the same tasks, though exactly how well it works compared to its rivals is up for debate.\n",
            "\n",
            "It is reportedly as powerful as OpenAI's o1 model - released at the end of last year - in tasks including mathematics and coding.\n",
            "\n",
            "\n",
            "Chunk 2:\n",
            "Like o1, R1 is a \"reasoning\" model. These models produce responses incrementally, simulating how humans reason through problems or ideas.\n",
            "\n",
            "Deepseek says it has been able to do this cheaply - researchers behind it claim it cost $6m (£4.8m) to train, a fraction of the \"over $100m\" alluded to by OpenAI boss Sam Altman when discussing GPT-4.\n",
            "\n",
            "It has also seemingly be able to minimise the impact of US restrictions on the most powerful chips reaching China.\n",
            "\n",
            "\n",
            "Chunk 3:\n",
            "DeepSeek's founder reportedly built up a store of Nvidia A100 chips, which have been banned from export to China since September 2022. Some experts believe he paired these chips with cheaper, less sophisticated ones - ending up with a much more efficient process.\n",
            "\n",
            "DeepSeek also uses less memory than its rivals, ultimately reducing the cost to perform tasks for users.\n",
            "\n",
            "\n",
            "Chunk 4:\n",
            "That combination of performance and lower cost helped DeepSeek's AI assistant become the most-downloaded free app on Apple's App Store when it was released in the US.\n",
            "\n",
            "The same day, it was hit with \"large-scale malicious attacks\", the company said, causing the company to temporary limit registrations.\n",
            "\n",
            "Its website also experienced outages.\n",
            "\n",
            "Like many other Chinese AI models - Baidu's Ernie or Doubao by ByteDance - DeepSeek is trained to avoid politically sensitive questions.\n",
            "\n",
            "\n",
            "Chunk 5:\n",
            "When the BBC asked the app what happened at Tiananmen Square on 4 June 1989, DeepSeek did not give any details about the massacre, a taboo topic in China, which is subject to government censorship.\n",
            "\n",
            "Who is behind DeepSeek?\n",
            "\n",
            "DeepSeek was founded in December 2023 by Liang Wenfeng, and released its first AI large language model the following year.\n",
            "\n",
            "\n",
            "Chunk 6:\n",
            "Not much is known about Mr Liang, who graduated from Zhejiang University with degrees in electronic information engineering and computer science. But he now finds himself in the international spotlight.\n",
            "\n",
            "He was recently seen at a meeting hosted by China's premier Li Qiang, reflecting DeepSeek's growing prominence in the AI industry.\n",
            "\n",
            "Unlike many American AI entrepreneurs who are from Silicon Valley, Mr Liang also has a background in finance.\n",
            "\n",
            "\n",
            "Chunk 7:\n",
            "He is the CEO of a hedge fund called High-Flyer, which uses AI to analyse financial data to make investment decisions - what is called quantitative trading. In 2019 High-Flyer became the first quant hedge fund in China to raise over 100 billion yuan ($13m).\n",
            "\n",
            "In a speech he gave that year, Liang said, \"If the US can develop its quantitative trading sector, why not China?\"\n",
            "\n",
            "In a rare interview last year, he said China's AI sector \"cannot remain a follower forever\" of US AI development.\n",
            "\n",
            "\n",
            "Chunk 8:\n",
            "Asked why DeepSeek's model surprised so many in Silicon Valley, Liang said: \"Their surprise stems from seeing a Chinese company join their game as an innovator, not just a follower - which is what most Chinese firms are accustomed to.\"\n",
            "\n",
            "But it has drawn scrutiny from global leaders.\n",
            "\n",
            "Australia has banned DeepSeek on government devices and systems, saying it poses a national security risk.\n",
            "\n",
            "\n",
            "Chunk 9:\n",
            "Several data protection authorities around the world have also asked DeepSeek to clarify how it handles personal information - which it stores on China-based servers.\n",
            "\n",
            "Italy blocked DeepSeek's app on 30 January and ordered the company to stop processing the personal information of its citizens over data protection concerns.\n",
            "\n",
            "Why were US companies like Nvidia hit?\n",
            "\n",
            "\n",
            "Chunk 10:\n",
            "Why were US companies like Nvidia hit?\n",
            "\n",
            "DeepSeek's achievements undercut the belief that bigger budgets and top-tier chips are the only ways of advancing AI, a prospect which has created uncertainty about the future of high-performance chips.\n",
            "\n",
            "\"DeepSeek has proven that cutting-edge AI models can be developed with limited compute resources,\" says Wei Sun, principal AI analyst at Counterpoint Research.\n",
            "\n",
            "\n",
            "Chunk 11:\n",
            "\"In contrast, OpenAI, valued at $157 billion, faces scrutiny over its ability to maintain a dominant edge in innovation or justify its massive valuation and expenditures without delivering significant returns.\"\n",
            "\n",
            "DeepSeek's apparently lower costs roiled financial markets on 27 January, leading the tech-heavy Nasdaq to fall more than 3% in a broad sell-off that included chip makers and data centres around the world.\n",
            "\n",
            "\n",
            "Chunk 12:\n",
            "Nvidia's stock price plunged 17% on Monday before it began to recover on Tuesday.\n",
            "\n",
            "The chip maker had been the most valuable company in the world, when measured by market capitalisation.\n",
            "\n",
            "But it fell to third place after Apple and Microsoft on Monday, when its market value shrank to $2.9tn from $3.5tn, Forbes reported.\n",
            "\n",
            "DeepSeek is a privately owned company, which means investors cannot buy shares of stock on any of the major exchanges.\n",
            "\n",
            "\n",
            "Chunk 13:\n",
            "China's DeepSeek AI shakes industry and dents America's swagger\n",
            "\n",
            "How has China reacted to DeepSeek's impact?\n",
            "\n",
            "DeepSeek's rise is a huge boost for the Chinese government, which has been seeking to build tech independent of the West.\n",
            "\n",
            "While the Communist Party is yet to comment, Chinese state media was eager to note that Silicon Valley and Wall Street giants were \"losing sleep\" over DeepSeek, which was \"overturning\" the US stock market.\n",
            "\n",
            "\n",
            "Chunk 14:\n",
            "\"In China, DeepSeek's advances are being celebrated as a testament to the country's growing technological prowess and self-reliance,\" says Marina Zhang, an associate professor at the University of Technology Sydney.\n",
            "\n",
            "\"The company's success is seen as a validation of China's Innovation 2.0, a new era of homegrown technological leadership driven by a younger generation of entrepreneurs.\"\n",
            "\n",
            "But she also warned that this sentiment may also lead to \"tech isolationism\".\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using LangChain for RAG Workflow**"
      ],
      "metadata": {
        "id": "8yoympq8CZYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Use Google Gemini embeddings to vectorize* *documents*"
      ],
      "metadata": {
        "id": "42cIPV_0Ca1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "id": "dONDQdo5Bg6E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "6DxsxQwgQvRA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 100\n",
        "batch = []\n",
        "\n",
        "# Create embeddings and upload to Pinecone in batches\n",
        "for i, doc in tqdm(enumerate(documents), total=len(documents), desc=\"Uploading to Pinecone\"):\n",
        "    vector = embeddings.embed_query(doc.page_content)\n",
        "\n",
        "    # Unique ID for each document (fallback if \"source\" is missing)\n",
        "    doc_id = doc.metadata.get(\"source\", f\"doc_{i}\")\n",
        "\n",
        "    # Append data to batch\n",
        "    batch.append((doc_id, vector, {\"text\": doc.page_content}))\n",
        "\n",
        "    # Upload in batches\n",
        "    if len(batch) >= batch_size:\n",
        "        index.upsert(batch)  # Perform batch upload\n",
        "        batch = []  # Clear batch\n",
        "\n",
        "# Upload any remaining chunks\n",
        "if batch:\n",
        "    index.upsert(batch)\n",
        "\n",
        "print(\"Successfully stored vectorized chunks in Pinecone!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPEsQFIelCRT",
        "outputId": "d7e771f7-6031-4766-a814-7ec14668432d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Uploading to Pinecone: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully stored vectorized chunks in Pinecone!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "4DjkeRqJCPkl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "63uK-DzYoVBN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "cX6yqveCqr6H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How is DeepSeek different from other AI Models?\"\n",
        "response = qa_chain.run(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRV2OYvprnfm",
        "outputId": "3f72a54d-e2fc-4148-b6e0-2c57ebc1f7cc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-555ba27f3ad9>:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = qa_chain.run(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepSeek distinguishes itself from other AI models in several key ways:\n",
            "\n",
            "* **Lower cost:**  It was reportedly trained for $6 million, a fraction of the cost of models like GPT-4.  This was achieved through efficient use of hardware and potentially by combining high-end and lower-end chips.\n",
            "\n",
            "* **Lower memory usage:** DeepSeek uses less memory than its rivals, leading to reduced operational costs.\n",
            "\n",
            "* **Performance:**  It's claimed to be comparable in performance to OpenAI's o1 model in tasks like mathematics and coding.  It's a \"reasoning\" model, similar to o1, producing responses incrementally.\n",
            "\n",
            "* **Circumvention of US chip restrictions:**  DeepSeek's development seemingly circumvented US restrictions on exporting high-performance chips to China, raising questions about the reliance on top-tier hardware for AI advancement.\n",
            "\n",
            "* **Market impact:** Its relatively low cost and high performance caused significant disruption in the AI market, leading to a sell-off in the stock prices of companies like Nvidia.\n",
            "\n",
            "* **Political sensitivity:** Like other Chinese AI models, DeepSeek is trained to avoid politically sensitive topics, reflecting the censorship environment in China.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector search\n",
        "def answer_to_user(query: str):\n",
        "#Vector search\n",
        "  vector_results = vector_store.similarity_search_with_score(query, k=2)\n",
        "# Pass Model vector search + Query\n",
        "  final_answer = llm.invoke(f\"ANSWER THIS QUERY: {query}, Here are some references to the answer {vector_results}\")\n",
        "  return final_answer"
      ],
      "metadata": {
        "id": "q3LbF5diojr4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_to_user(\"Is DeepSeek an AI model?\")\n",
        "answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "H7uI9eXipraz",
        "outputId": "c85552fb-034b-415b-a116-5415fa8e4534"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the provided text, DeepSeek is an AI-powered chatbot.  The document explicitly states that it is \"a free AI-powered chatbot\" and describes its capabilities as comparable to other large language models like ChatGPT and OpenAI\\'s o1 model.  Therefore, the answer is **yes**.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_to_user(\"How has China reacted to DeepSeek's impact?\")\n",
        "answer.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "S8UkeGsnpV-L",
        "outputId": "be7f7d31-b11b-445c-8128-917e8fecd4d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'China\\'s reaction to DeepSeek\\'s impact has been largely positive and celebratory.  While the Communist Party hasn\\'t issued an official statement, Chinese state media highlighted DeepSeek\\'s success as a challenge to Silicon Valley and Wall Street, emphasizing its impact on the US stock market.  The achievement is viewed as a testament to China\\'s growing technological prowess and self-reliance, validating its \"Innovation 2.0\" initiative aimed at homegrown technological leadership.  However, there\\'s also a warning that this positive sentiment could potentially lead to \"tech isolationism.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploy as an API with FastAPI"
      ],
      "metadata": {
        "id": "fGdaF2sPwQan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi # Installs the fastapi library\n",
        "!pip install python-multipart # uvicorn dependency\n",
        "!pip install uvicorn # ASGI server\n",
        "\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "import shutil\n",
        "import docx2txt\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/upload/\")\n",
        "async def upload_docx(file: UploadFile = File(...)):\n",
        "    file_location = f\"./{file.filename}\"\n",
        "    with open(file_location, \"wb\") as buffer:\n",
        "        shutil.copyfileobj(file.file, buffer)\n",
        "\n",
        "    text = docx2txt.process(file_location)\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    docs = text_splitter.create_documents([text])\n",
        "\n",
        "    batch = []\n",
        "    for i, doc in enumerate(docs):\n",
        "        vector = embeddings.embed_query(doc.page_content)\n",
        "        doc_id = f\"doc_{i}\"\n",
        "        batch.append((doc_id, vector, {\"text\": doc.page_content}))\n",
        "\n",
        "    index.upsert(batch)\n",
        "\n",
        "    return {\"message\": \"Document uploaded and indexed successfully!\"}\n",
        "\n",
        "@app.post(\"/query/\")\n",
        "def query_rag(question: str):\n",
        "    query_vector = embeddings.embed_query(question)\n",
        "    results = index.query(vector=query_vector, top_k=1, include_metadata=True)\n",
        "\n",
        "    context = \"\\n\".join([match[\"metadata\"][\"text\"] for match in results[\"matches\"]])\n",
        "    return {\"question\": question, \"answer\": context}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KkVK3bavwO7J",
        "outputId": "2223560c-7c13-421d-ab9b-5e6c87c3466f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.8)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.45.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.46.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uvicorn rag_api.ipynb:app --reload --host 0.0.0.0 --port 8000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPmTpP5jQ7dO",
        "outputId": "7eebfb4a-fd55-4c03-ca21-751482b41b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content']\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m59104\u001b[0m] using \u001b[36m\u001b[1mStatReload\u001b[0m\n",
            "Process SpawnProcess-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/_subprocess.py\", line 80, in subprocess_started\n",
            "    target(sockets=sockets)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    await self._serve(sockets)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 77, in _serve\n",
            "    config.load()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/config.py\", line 435, in load\n",
            "    self.loaded_app = import_from_string(self.app)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/importer.py\", line 22, in import_from_string\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/importer.py\", line 19, in import_from_string\n",
            "    module = importlib.import_module(module_str)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1126, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1140, in _find_and_load_unlocked\n",
            "ModuleNotFoundError: No module named 'rag_api'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST -F \"file=/content/DeepSeek_txt.docx\" http://127.0.0.1:8000/upload/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7zm-lE1yiQW",
        "outputId": "972acf5a-b1bd-4049-8774-b1fd09ed4ea6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (7) Failed to connect to 127.0.0.1 port 8000 after 0 ms: Connection refused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST \"http://127.0.0.1:8000/query/?question=What are the DeepSeek challenges?\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyQcVs-ayug3",
        "outputId": "7bb2917e-058f-4859-8770-090f426b50ce"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (3) URL using bad/illegal format or missing URL\n"
          ]
        }
      ]
    }
  ]
}